
@article{turney_frequency_2010,
  title = {From Frequency to Meaning: {{Vector Space Models}} of Semantics},
  volume = {37},
  doi = {10.1613/jair.2934},
  shorttitle = {From Frequency to Meaning},
  number = {1},
  journaltitle = {Journal of Artificial Intelligence Research},
  date = {2010},
  pages = {141--188},
  keywords = {computational linguistics,collocation,corpus linguistics,distributional semantics,semantic vector},
  author = {Turney, Peter D. and Pantel, Patrick},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Journal Article/Turney_Pantel_2010_From frequency to meaning.pdf}
}

@incollection{levshina_radically_2014,
  langid = {english},
  location = {{Berlin}},
  title = {A Radically Data-Driven Construction Grammar: {{Experiments}} with {{Dutch}} Causative Constructions},
  shorttitle = {A Radically Data-Driven {{Construction Grammar}}},
  booktitle = {Extending the Scope of Construction Grammar},
  publisher = {{Mouton de Gruyter}},
  date = {2014},
  pages = {17-46},
  author = {Levshina, Natalia and Heylen, Kris},
  editor = {Boogaart, Ronny and Colleman, Timothy and Rutten, Gijsbert},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Book Section/Levshina_Heylen_2014_A radically data-driven Construction Grammar.pdf}
}

@article{levshina_geographic_2014,
  langid = {english},
  title = {Geographic Variation of {\emph{Quite}} + {{ADJ}} in Twenty National Varieties of {{English}}: {{A}} Pilot Study},
  volume = {2},
  doi = {10.1515/gcla-2014-0008},
  shorttitle = {Geographic Variation of Quite + {{ADJ}} in Twenty National Varieties of {{English}}},
  abstract = {This paper aims to show how large-scale corpus data can be used for bottom-up modelling of semantic differences between geographical variants of one construction. More specifically, it investigates the geographic variation of quite as a degree modifier of adjectives in twenty national written varieties of English. Based on semantic classes of more than 6,000 adjectives in almost 240,000 occurrences of quite + ADJ from the Global Web-based English corpus, as well as additional data collected directly from the World Wide Web, the quantitative analyses reveal systematic geographic differences in the use of quite. In addition, a distributional Vector Space Model is created that represents the aggregate similarities and differences between the geographic variants of quite + ADJ in a clustering solution, which is interpreted with the help of a distinctive collexeme analysis.},
  number = {1},
  journaltitle = {Yearbook of the German Cognitive Linguistics Association},
  date = {2014},
  pages = {109-126},
  keywords = {quite,degree modifier,GloWbE corpus,geographic variation,Vector Space models},
  author = {Levshina, Natalia},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Journal Article/Levshina_2014_Geographic variation of quite + ADJ in twenty national varieties of English.pdf}
}

@article{hilpert_meaning_2015,
  title = {Meaning Change in a Petri Dish: Constructions, Semantic Vector Spaces, and Motion Charts},
  volume = {1},
  issn = {2199-174X},
  doi = {10.1515/lingvan-2015-0013},
  shorttitle = {Meaning Change in a Petri Dish},
  number = {1},
  journaltitle = {Linguistics Vanguard},
  date = {2015-01-01},
  author = {Hilpert, Martin and Perek, Florent},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Journal Article/Hilpert_Perek_2015_Meaning change in a petri dish.pdf}
}

@Manual{wickham_tidyr_2018,
    title = {tidyr: Easily Tidy Data with 'spread()' and 'gather()' Functions},
    author = {Hadley Wickham and Lionel Henry},
    year = {2018},
    note = {R package version 0.8.2},
    url = {https://CRAN.R-project.org/package=tidyr},
  }

@Manual{henry_purrr_2019,
    title = {purrr: Functional Programming Tools},
    author = {Lionel Henry and Hadley Wickham},
    year = {2019},
    note = {R package version 0.3.0},
    url = {https://CRAN.R-project.org/package=purrr},
  }

@Manual{wickham_readr_2018,
    title = {readr: Read Rectangular Text Data},
    author = {Hadley Wickham and Jim Hester and Romain Francois},
    year = {2018},
    note = {R package version 1.3.1},
    url = {https://CRAN.R-project.org/package=readr},
  }

@Manual{wickham_stringr_2018,
    title = {stringr: Simple, Consistent Wrappers for Common String Operations},
    author = {Hadley Wickham},
    year = {2018},
    note = {R package version 1.3.1},
    url = {https://CRAN.R-project.org/package=stringr},
  }

@Manual{muller_tibble_2019,
    title = {tibble: Simple Data Frames},
    author = {Kirill Müller and Hadley Wickham},
    year = {2019},
    note = {R package version 2.0.1},
    url = {https://CRAN.R-project.org/package=tibble},
  }

@article{erk_vector_2012,
  title = {Vector Space Models of Word Meaning and Phrase Meaning: {{A}} Survey},
  volume = {6},
  issn = {1749818X},
  doi = {10.1002/lnco.362},
  shorttitle = {Vector {{Space Models}} of {{Word Meaning}} and {{Phrase Meaning}}},
  abstract = {Distributional models represent a word through the contexts in which it has been observed. They can be used to predict similarity in meaning, based on the distributional hypothesis, which states that two words that occur in similar contexts tend to have similar meanings. Distributional approaches are often implemented in vector space models. They represent a word as a point in high-dimensional space, where each dimension stands for a context item, and a word's coordinates represent its context counts. Occurrence in similar contexts then means proximity in space. In this survey we look at the use of vector space models to describe the meaning of words and phrases: the phenomena that vector space models address, and the techniques that they use to do so. Many word meaning phenomena can be described in terms of semantic similarity: synonymy, priming, categorization, and the typicality of a predicate's arguments. But vector space models can do more than just predict semantic similarity. They are a very flexible tool, because they can make use of all of linear algebra, with all its data structures and operations. The dimensions of a vector space can stand for many things: context words, or non-linguistic context like images, or properties of a concept. And vector space models can use matrices or higher-order arrays instead of vectors for representing more complex relationships. Polysemy is a tough problem for distributional approaches, as a representation that is learned from all of a word's contexts will conflate the different senses of the word. It can be addressed, using either clustering or vector combination techniques. Finally, we look at vector space models for phrases, which are usually constructed by combining word vectors. Vector space models for phrases can predict phrase similarity, and some argue that they can form the basis for a general-purpose representation framework for natural language semantics.},
  number = {10},
  journaltitle = {Language \& Linguistics Compass},
  shortjournal = {Language \& Linguistics Compass},
  date = {2012-10},
  pages = {635-653},
  keywords = {LINGUISTIC analysis (Linguistics),PHRASEOLOGY,SEMANTICS,SURVEYS,DATA structures (Computer science),VECTOR spaces,Semantics},
  author = {Erk, Katrin},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Journal Article/Erk_2012_Vector Space Models of Word Meaning and Phrase Meaning.pdf}
}

@article{hilpert_change_2016,
  title = {Change in Modal Meanings},
  volume = {8},
  issn = {18761933},
  doi = {10.1075/cf.8.1.05hil},
  abstract = {This paper discusses how modal auxiliaries fit into a constructional view of language and how this view allows us to think in new ways about diachronic meaning change in modal auxiliaries. These issues will be illustrated on the basis of a diachronic corpus-based study of the modal auxiliary may, specifically focusing on changes in its collocational preferences during the past 200 years. The main point of this paper is the claim that a constructional view needs to take account of the mutual associations between modal auxiliaries and the lexical elements with which they occur. Changes in these mutual associations are usefully understood as change in a complex network of constructions.},
  number = {1},
  journaltitle = {Constructions \& Frames},
  shortjournal = {Constructions \& Frames},
  date = {2016-01},
  pages = {66-85},
  keywords = {COLLOCATION (Linguistics),MODALITY (Linguistics),SEMANTICS,construction grammar,modality,Auxiliaries (Grammar),collocational change,modal constructions,semantic change,semantic vector space modeling,Construction grammar,Semantics},
  author = {Hilpert, Martin},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Journal Article/Hilpert_2016_Change in modal meanings.pdf}
}

@article{perek_using_2016,
  title = {Using Distributional Semantics to Study Syntactic Productivity in Diachrony: {{A}} Case Study},
  volume = {54},
  issn = {0024-3949},
  doi = {10.1515/ling-2015-0043},
  shorttitle = {Using Distributional Semantics to Study Syntactic Productivity in Diachrony},
  abstract = {This paper investigates syntactic productivity in diachrony with a data-driven approach. Previous research indicates that syntactic productivity (the property of grammatical constructions to attract new lexical fillers) is largely driven by semantics, which calls for an operationalization of lexical meaning in the context of empirical studies. It is suggested that distributional semantics can fulfill this role by providing a measure of semantic similarity between words that is derived from lexical co-occurrences in large text corpora. On the basis of a case study of the construction “V the hell out of NP”, e.g., You scared the hell out of me, it is shown that distributional semantics not only appropriately captures how the verbs in the distribution of the construction are related, but also enables the use of visualization techniques and statistical modeling to analyze the semantic development of a construction over time and identify the determinants of syntactic productivity in naturally occurring data.},
  number = {1},
  journaltitle = {Linguistics},
  date = {2016},
  pages = {149--188},
  author = {Perek, Florent},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Journal Article/Perek_2016_Using distributional semantics to study syntactic productivity in diachrony.pdf}
}

@inproceedings{pennington2014glove,
  title = {{{GloVe}}: {{Global Vectors}} for {{Word Representation}}},
  url = {http://www.aclweb.org/anthology/D14-1162},
  booktitle = {Empirical {{Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  date = {2014},
  pages = {1532-1543},
  keywords = {Vector Space models},
  author = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher D.},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Conference Paper/Pennington et al_2014_GloVe.pdf}
}

@article{hamilton_diachronic_2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1605.09096},
  primaryClass = {cs},
  title = {Diachronic {{Word Embeddings Reveal Statistical Laws}} of {{Semantic Change}}},
  url = {http://arxiv.org/abs/1605.09096},
  abstract = {Understanding how words change their meanings over time is key to models of language and cultural evolution, but historical data on meaning is scarce, making theories hard to develop and test. Word embeddings show promise as a diachronic tool, but have not been carefully evaluated. We develop a robust methodology for quantifying semantic change by evaluating word embeddings (PPMI, SVD, word2vec) against known historical changes. We then use this methodology to reveal statistical laws of semantic evolution. Using six historical corpora spanning four languages and two centuries, we propose two quantitative laws of semantic change: (i) the law of conformity---the rate of semantic change scales with an inverse power-law of word frequency; (ii) the law of innovation---independent of frequency, words that are more polysemous have higher rates of semantic change.},
  urldate = {2017-05-01},
  date = {2016-05-29},
  keywords = {Computer Science - Computation and Language,Vector Space models},
  author = {Hamilton, William L. and Leskovec, Jure and Jurafsky, Dan},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Journal Article/Hamilton et al_2016_Diachronic Word Embeddings Reveal Statistical Laws of Semantic Change.pdf}
}

@unpublished{musgrave_space_2016,
  venue = {{Melbourne}},
  title = {Space Vector Models and Empirical {{Saussurean}} Semantics},
  url = {https://figshare.com/articles/Space_vector_models_and_empirical_Saussurean_semantics/4036164},
  type = {Paper},
  doi = {https://doi.org/10.4225/03/58045ef04d37d},
  eventtitle = {Australian {{Linguistic Society}} ({{ALS}}) 2016},
  date = {2016-12-07/2016-12-09},
  author = {Musgrave, Simon and Gaby, Alice and Rajeg, Gede Primahadi Wijaya}
}

@article{perek_recent_2016,
  title = {Recent Change in the Productivity and Schematicity of the {\emph{Way}}-Construction: {{A}} Distributional Semantic Analysis},
  issn = {1613-7027, 1613-7035},
  doi = {10.1515/cllt-2016-0014},
  shorttitle = {Recent Change in the Productivity and Schematicity of the Way-Construction},
  journaltitle = {Corpus Linguistics and Linguistic Theory},
  date = {2016-01-18},
  keywords = {corpus linguistics,distributional semantics},
  author = {Perek, Florent},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Journal Article/Perek_2016_Recent change in the productivity and schematicity of the.pdf}
}

@article{hilpert_using_2017,
  title = {Using Token-Based Semantic Vector Spaces for Corpus-Linguistic Analyses: {{From}} Practical Applications to Tests of Theoretical Claims},
  volume = {0},
  issn = {1613-7027, 1613-7035},
  doi = {10.1515/cllt-2017-0009},
  shorttitle = {Using Token-Based Semantic Vector Spaces for Corpus-Linguistic Analyses},
  number = {0},
  journaltitle = {Corpus Linguistics and Linguistic Theory},
  date = {2017-01-26},
  author = {Hilpert, Martin and Saavedra, David Correia},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Journal Article/Hilpert_Saavedra_2017_Using token-based semantic vector spaces for corpus-linguistic analyses.pdf}
}

@article{perek_distributional_2017,
  langid = {english},
  title = {A Distributional Semantic Approach to the Periodization of Change in the Productivity of Constructions},
  volume = {22},
  issn = {1384-6655, 1569-9811},
  doi = {10.1075/ijcl.16128.per},
  number = {4},
  journaltitle = {International Journal of Corpus Linguistics},
  date = {2017-12-01},
  pages = {490-520},
  author = {Perek, Florent and Hilpert, Martin},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Journal Article/Perek_Hilpert_2017_A distributional semantic approach to the periodization of change in the.pdf}
}

@software{schmidt_wordvectors_2017,
  title = {{{wordVectors}}: {{Tools}} for Creating and Analyzing Vector-Space Models of Texts},
  url = {http://github.com/bmschmidt/wordVectors},
  version = {2.0},
  date = {2017},
  author = {Schmidt, Ben and Li, Jian}
}

@article{rajeg_vector_2019,
	title = {Vector Space Models and the usage patterns of Indonesian denominal verbs: A case study of verbs with {meN}-, {meN}-/-kan, and {meN}-/-i affixes},
	volume = {67},
	url = {http://repository.tufs.ac.jp/handle/10108/94452},
	series = {Linguistic studies using large annotated corpora},
	pages = {35--76},
	journaltitle = {{NUSA}},
	author = {Rajeg, Gede Primahadi Wijaya and Denistia, Karlina and Musgrave, Simon},
	editor = {Nomoto, Hiroki and Moeljadi, David},
	urldate = {2020-04-01},
	date = {2019}
}

@article{nomoto_linguistic_2019,
	title = {Linguistic studies using large annotated corpora: Introduction},
	volume = {67},
	url = {http://repository.tufs.ac.jp/handle/10108/94450},
	series = {Linguistic studies using large annotated corpora},
	pages = {1--6},
	journaltitle = {{NUSA}},
	author = {Nomoto, Hiroki and Moeljadi, David},
	editor = {Nomoto, Hiroki and Moeljadi, David},
	urldate = {2020-04-01},
	date = {2019}
}

@unpublished{rajeg_semantic_2018,
  langid = {english},
  venue = {{The University of California, Los Angeles}},
  title = {Semantic Vector Space Model and the Usage Patterns of {{Indonesian}} Denominal Verbs with {{{\emph{meN}}}}{\emph{-}}, {{{\emph{meN}}}}{\emph{- -Kan}}, and {{{\emph{meN}}}}{\emph{- -i}} Affixes},
  url = {http://ismil.shh.mpg.de/20/abstracts/Rajeg.pdf},
  eventtitle = {Twenty-{{Second International Symposium}} on {{Malay}}/{{Indonesian Linguistics}} ({{ISMIL}} 22)},
  date = {2018-05-11/2018-05-12},
  author = {Rajeg, Gede Primahadi Wijaya and Denistia, Karlina and Musgrave, Simon},
  doi = {10.4225/03/5acffc60eb649}
}

@book{chollet_deep_2018,
  location = {{Shelter Island, NY}},
  title = {Deep Learning with {{R}}},
  isbn = {978-1-61729-554-6},
  abstract = {Introduces deep learning systems using the powerful Keras library and its R language interface. The book builds your understanding of deep learning through intuitive explanations and practical examples},
  pagetotal = {335},
  publisher = {{Manning Publications Co}},
  date = {2018},
  keywords = {Data processing,R (Computer program language),Technological innovations,Artificial intelligence,Computer vision,Machine learning,Mathematical statistics,Neural networks (Computer science)},
  author = {Chollet, François and Allaire, Joseph J.},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Book/Chollet_Allaire_2018_Deep learning with R.pdf},
  note = {OCLC: on1022850710}
}

@article{miller_contextual_1991,
  langid = {english},
  title = {Contextual Correlates of Semantic Similarity},
  volume = {6},
  issn = {0169-0965, 1464-0732},
  doi = {10.1080/01690969108406936},
  number = {1},
  journaltitle = {Language and Cognitive Processes},
  date = {1991-01},
  pages = {1-28},
  author = {Miller, George A. and Charles, Walter G.},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Journal Article/Miller_Charles_1991_Contextual correlates of semantic similarity.pdf}
}

@inproceedings{peirsman_word_2008,
  location = {{Hamburg, Germany}},
  title = {Word {{Space Models}} of Semantic Similarity and Relatedness},
  eventtitle = {European {{Summer School}} in {{Logic}}, {{Language}} and {{Information}} ({{ESSLLI}})},
  booktitle = {Proceedings of the 13th {{ESSLLI Student Session}}},
  publisher = {{Springer}},
  date = {2008},
  pages = {143-152},
  author = {Peirsman, Yves},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Conference Paper/Peirsman_2008_Word Space Models of semantic similarity and relatedness.pdf}
}

@article{mikolov_efficient_2013,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1301.3781},
  primaryClass = {cs},
  title = {Efficient {{Estimation}} of {{Word Representations}} in {{Vector Space}}},
  url = {http://arxiv.org/abs/1301.3781},
  abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
  urldate = {2018-12-14},
  date = {2013-01-16},
  keywords = {Computer Science - Computation and Language},
  author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Journal Article/Mikolov et al_2013_Efficient Estimation of Word Representations in Vector Space.pdf}
}

@article{mikolov_distributed_2013,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1310.4546},
  primaryClass = {cs, stat},
  title = {Distributed {{Representations}} of {{Words}} and {{Phrases}} and Their {{Compositionality}}},
  url = {http://arxiv.org/abs/1310.4546},
  abstract = {The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of "Canada" and "Air" cannot be easily combined to obtain "Air Canada". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.},
  urldate = {2018-12-14},
  date = {2013-10-16},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning},
  author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Journal Article/Mikolov et al_2013_Distributed Representations of Words and Phrases and their Compositionality.pdf}
}

@inproceedings{mikolov_linguistic_2013,
  location = {{Atlanta, Georgia}},
  title = {Linguistic {{Regularities}} in {{Continuous Space Word Representations}}},
  url = {http://www.aclweb.org/anthology/N13-1090},
  booktitle = {Proceedings of the 2013 {{Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}}},
  publisher = {{Association for Computational Linguistics}},
  urldate = {2018-12-14},
  date = {2013-06},
  pages = {746--751},
  author = {Mikolov, Tomas and Yih, Wen-tau and Zweig, Geoffrey},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Conference Paper/Mikolov et al_2013_Linguistic Regularities in Continuous Space Word Representations.pdf}
}

@incollection{allan_tracing_2012,
  location = {{Berlin}},
  title = {Tracing Semantic Change with {{Latent Semantic Analysis}}},
  isbn = {978-3-11-025288-0},
  number = {73},
  booktitle = {Current Methods in Historical Semantics},
  series = {Topics in {{English}} Linguistics},
  publisher = {{De Gruyter Mouton}},
  date = {2012},
  pages = {161-183},
  keywords = {ENGLISH language,Semantics; Historical},
  author = {Sagi, Eyal and Kaufmann, Stefan and Clark, Brady},
  editor = {Allan, Kathryn and Robinson, Justyna A.}
}

@article{harris_distributional_1954,
  title = {Distributional {{Structure}}},
  volume = {10},
  issn = {0043-7956},
  doi = {10.1080/00437956.1954.11659520},
  number = {2-3},
  journaltitle = {WORD},
  date = {1954-08-01},
  pages = {146-162},
  author = {Harris, Zellig S.},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Journal Article/Harris_1954_Distributional Structure.pdf}
}

@inproceedings{kiela_systematic_2014,
  location = {{Gothenburg, Sweden}},
  title = {A {{Systematic Study}} of {{Semantic Vector Space Model Parameters}}},
  url = {http://www.aclweb.org/anthology/W14-1503},
  booktitle = {Proceedings of the 2nd {{Workshop}} on {{Continuous Vector Space Models}} and Their {{Compositionality}} ({{CVSC}})},
  publisher = {{Association for Computational Linguistics}},
  urldate = {2018-12-29},
  date = {2014-04},
  pages = {21--30},
  author = {Kiela, Douwe and Clark, Stephen},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Conference Paper/Kiela_Clark_2014_A Systematic Study of Semantic Vector Space Model Parameters.pdf}
}

@incollection{lappin_vector_2015,
  location = {{Hoboken}},
  title = {Vector Space Models of Lexical Meaning},
  edition = {Second Edition},
  isbn = {978-0-470-67073-6},
  booktitle = {The {{Handbook}} of {{Contemporary}} Semantic Theory},
  publisher = {{John Wiley \& Sons}},
  date = {2015},
  pages = {493-522},
  keywords = {SEMANTICS,SEMANTICS (Philosophy),Handbooks; manuals; etc,Semantics},
  author = {Clark, Stephen},
  editor = {Lappin, Shalom and Fox, Chris}
}

@inproceedings{baroni_dont_2014,
  location = {{Baltimore, Maryland}},
  title = {Don't Count, Predict! {{A}} Systematic Comparison of Context-Counting vs. Context-Predicting Semantic Vectors},
  url = {http://www.aclweb.org/anthology/P14-1023},
  booktitle = {Proceedings of the 52nd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  publisher = {{Association for Computational Linguistics}},
  urldate = {2019-01-02},
  date = {2014-06},
  pages = {238--247},
  author = {Baroni, Marco and Dinu, Georgiana and Kruszewski, Germán},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Conference Paper/Baroni et al_2014_Don't count, predict.pdf}
}

@online{schmidt_vector_2015,
  title = {Vector {{Space Models}} for the {{Digital Humanities}}},
  url = {http://bookworm.benschmidt.org/posts/2015-10-25-Word-Embeddings.html},
  urldate = {2016-01-24},
  date = {2015-10-25},
  author = {Schmidt, Ben},
  file = {/Users/Primahadi/Documents/Zotero/storage/RWWVU7H7/2015-10-25-Word-Embeddings.html}
}

@article{heylen_monitoring_2015,
  title = {Monitoring Polysemy: {{Word}} Space Models as a Tool for Large-Scale Lexical Semantic Analysis},
  volume = {157},
  issn = {0024-3841},
  doi = {10.1016/j.lingua.2014.12.001},
  shorttitle = {Monitoring Polysemy},
  abstract = {This paper demonstrates how token-level Word Space Models (a distributional semantic technique that was originally developed in statistical natural language processing) can be developed into a heuristic tool to support lexicological and lexicographical analyses of large amounts of corpus data. The paper provides a non-technical introduction to the statistical methods and illustrates with a case study analysis of the Dutch polysemous noun ‘monitor’ how token-level Word Space Models in combination with visualisation techniques allow human analysts to identify semantic patterns in an unstructured set of attestations. Additionally, we show how the interactive features of the visualisation make it possible to explore the effect of different contextual factors on the distributional model.},
  journaltitle = {Lingua},
  shortjournal = {Lingua},
  series = {Polysemy: {{Current Perspectives}} and {{Approaches}}},
  date = {2015-04},
  pages = {153-172},
  keywords = {lexical semantics,Distributional models,Statistical analysis,Visual analytics},
  author = {Heylen, Kris and Wielfaert, Thomas and Speelman, Dirk and Geeraerts, Dirk},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Journal Article/Heylen et al_2015_Monitoring polysemy.pdf}
}


@book{gries_statistics_2013,
  langid = {english},
  location = {{Berlin}},
  title = {Statistics for Linguistics with {{R}}: {{A}} Practical Introduction},
  edition = {2nd},
  isbn = {978-3-11-030747-4},
  publisher = {{Mouton de Gruyter}},
  date = {2013},
  author = {Gries, Stefan Th.},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Book/Gries_2013_Statistics for linguistics with R.pdf}
}

@book{baayen_analyzing_2008,
  location = {{Cambridge, UK ; New York}},
  title = {Analyzing Linguistic Data: {{A}} Practical Introduction to Statistics Using {{R}}},
  isbn = {978-0-521-88259-0 978-0-521-70918-7},
  shorttitle = {Analyzing Linguistic Data},
  pagetotal = {353},
  publisher = {{Cambridge University Press}},
  date = {2008},
  keywords = {computational linguistics,Linguistics,MATHEMATICAL linguistics,R (Computer program language),R (computerprogramma),Statistische methoden,Linguïstiek,Statistical methods,Computational linguistics},
  author = {Baayen, R. Harald},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Book/Baayen_2008_Analyzing linguistic data.pdf}
}

@book{levshina_how_2015,
  langid = {english},
  title = {How to Do {{Linguistics}} with {{R}}: {{Data}} Exploration and Statistical Analysis},
  isbn = {978-90-272-6845-7},
  shorttitle = {How to Do {{Linguistics}} with {{R}}},
  abstract = {This book provides a linguist with a statistical toolkit for exploration and analysis of linguistic data. It employs R, a free software environment for statistical computing, which is increasingly popular among linguists. How to do Linguistics with R: Data exploration and statistical analysis is unique in its scope, as it covers a wide range of classical and cutting-edge statistical methods, including different flavours of regression analysis and ANOVA, random forests and conditional inference trees, as well as specific linguistic approaches, among which are Behavioural Profiles, Vector Space Models and various measures of association between words and constructions. The statistical topics are presented comprehensively, but without too much technical detail, and illustrated with linguistic case studies that answer non-trivial research questions. The book also demonstrates how to visualize linguistic data with the help of attractive informative graphs, including the popular ggplot2 system and Google visualization tools.},
  pagetotal = {457},
  publisher = {{John Benjamins Publishing Company}},
  date = {2015-11-15},
  keywords = {LANGUAGE ARTS & DISCIPLINES / Linguistics / General,Computers / Natural Language Processing,Language Arts & Disciplines / Linguistics / General},
  author = {Levshina, Natalia},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Book/Levshina_2015_How to do Linguistics with R.pdf}
}

@Manual{wickham_dplyr_2018,
    title = {dplyr: A Grammar of Data Manipulation},
    author = {Hadley Wickham and Romain François and Lionel Henry and Kirill Müller},
    year = {2018},
    note = {R package version 0.7.8},
    url = {https://CRAN.R-project.org/package=dplyr},
  }

@Book{wickham_ggplot2_2016,
    author = {Hadley Wickham},
    title = {ggplot2: Elegant Graphics for Data Analysis},
    publisher = {Springer-Verlag New York},
    year = {2016},
    isbn = {978-3-319-24277-4},
    url = {http://ggplot2.org},
  }

@book{desagulier_corpus_2017,
  location = {{Cham}},
  title = {Corpus {{Linguistics}} and {{Statistics}} with {{R}}},
  isbn = {978-3-319-64570-4 978-3-319-64572-8},
  publisher = {{Springer International Publishing}},
  date = {2017},
  author = {Desagulier, Guillaume},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Book/Desagulier_2017_Corpus Linguistics and Statistics with R.pdf},
  doi = {10.1007/978-3-319-64572-8}
}

@book{gries_quantitative_2017,
  langid = {english},
  location = {{New York}},
  title = {Quantitative Corpus Linguistics with {{R}}: {{A}} Practical Introduction},
  edition = {Second edition},
  isbn = {978-1-138-81628-2},
  shorttitle = {Quantitative {{Corpus Linguistics}} with {{R}}},
  abstract = {As in its first edition, the new edition of Quantitative Corpus Linguistics with R demonstrates how to process corpus-linguistic data with the open-source programming language and environment R. Geared in general towards linguists working with observational data, and particularly corpus linguists, it introduces R programming with emphasis on:  data processing and manipulation in general; text processing with and without regular expressions of large bodies of textual and/or literary data, and; basic aspects of statistical analysis and visualization. This book is extremely hands-on and leads the reader through dozens of small applications as well as larger case studies. Along with an array of exercise boxes and separate answer keys, the text features a didactic sequential approach in case studies by way of subsections that zoom in to every programming problem. The companion website to the book contains all relevant R code (amounting to approximately 7,000 lines of heavily commented code), most of the data sets as well as pointers to others, and a dedicated Google newsgroup. This new edition is ideal for both researchers in corpus linguistics and instructors who want to promote hands-on approaches to data in corpus linguistics courses.},
  pagetotal = {286},
  publisher = {{Routledge}},
  date = {2017},
  author = {Gries, Stefan Th.}
}

@report{quasthoff_indonesian_2013,
  location = {{Leipzig, Germany}},
  title = {Indonesian Corpora},
  url = {http://asvdoku.informatik.uni-leipzig.de/corpora/data/uploads/corpus-building-vol7-ind.pdf},
  number = {7},
  series = {Technical {{Report Series}} on {{Corpus Building}}},
  institution = {{Abteilung Automatische Sprachverarbeitung, Institut für Informatik, Universität Leipzig}},
  urldate = {2015-07-26},
  date = {2013-04},
  author = {Quasthoff, Uwe and Goldhahn, Dirk},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Report/Quasthoff_Goldhahn_2013_Indonesian corpora.pdf}
}

@inproceedings{quasthoff_corpus_2006,
  location = {{Genoa, Italy}},
  title = {Corpus Portal for Search in Monolingual Corpora},
  isbn = {978-2-9517408-7-7},
  url = {http://corpora2.informatik.uni-leipzig.de/download/CorpusPortal.pdf},
  booktitle = {Proceedings of the 5th {{Language Resources}} and {{Evaluation Conference}} ({{LREC}}) 2006},
  urldate = {2014-03-05},
  date = {2006},
  pages = {1799-1802},
  author = {Quasthoff, Uwe and Richter, Matthias and Biemann, Christian},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Conference Paper/Biemann et al_2006_Corpus portal for search in monolingual corpora.pdf}
}

@inproceedings{biemann_leipzig_2007,
  location = {{University of Birmingham, UK}},
  title = {The {{Leipzig Corpora Collection}}: {{Monolingual}} Corpora of Standard Size},
  isbn = {1747-9398},
  url = {http://ucrel.lancs.ac.uk/publications/CL2007/paper/190_Paper.pdf},
  eventtitle = {{{CL2007}}},
  booktitle = {Proceedings of the {{Corpus Linguistics Conference}}},
  urldate = {2014-03-05},
  date = {2007},
  author = {Biemann, Chris and Heyer, Gerhard and Quasthoff, Uwe and Richter, Matthias},
  editor = {Davies, Matthew and Rayson, Paul and Hunston, Susan and Danielsson, Pernilla},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Conference Paper/Biemann et al_2007_The Leipzig Corpora Collection.pdf}
}

@inproceedings{goldhahn_building_2012,
  location = {{Istanbul}},
  title = {Building Large Monolingual Dictionaries at the {{Leipzig Corpora Collection}}: {{From}} 100 to 200 Languages},
  isbn = {978-2-9517408-7-7},
  url = {http://www.lrec-conf.org/proceedings/lrec2012/pdf/327_Paper.pdf},
  booktitle = {Proceedings of the 8th {{Language Resources}} and {{Evaluation Conference}} ({{LREC}}) 2012},
  urldate = {2014-03-05},
  date = {2012},
  pages = {759-765},
  author = {Goldhahn, Dirk and Eckart, Thomas and Quasthoff, Uwe},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Conference Paper/Goldhahn et al_2012_Building large monolingual dictionaries at the Leipzig Corpora Collection.pdf}
}

@inproceedings{larasati_indonesian_2011,
  langid = {english},
  title = {Indonesian {{Morphology Tool}} ({{MorphInd}}): {{Towards}} an {{Indonesian Corpus}}},
  isbn = {978-3-642-23137-7 978-3-642-23138-4},
  doi = {10.1007/978-3-642-23138-4_8},
  shorttitle = {Indonesian {{Morphology Tool}} ({{MorphInd}})},
  abstract = {This paper describes a robust finite state morphology tool for Indonesian (MorphInd), which handles both morphological analysis and lemmatization for a given surface word form so that it is suitable for further language processing. MorphInd has wider coverage on handling Indonesian derivational and inflectional morphology compared to an existing Indonesian morphological analyzer [1], along with a more detailed tagset. MorphInd outputs the analysis in the form of segmented morphemes along with the morphological tags. The implementation was done using finite state technology by adopting the two-level morphology approach implemented in Foma. It achieved 84.6\% of coverage on a preliminary stage Indonesian corpus where it mostly fails to capture the proper nouns and foreign words as expected initially.},
  eventtitle = {International {{Workshop}} on {{Systems}} and {{Frameworks}} for {{Computational Morphology}}},
  booktitle = {Systems and {{Frameworks}} for {{Computational Morphology}}},
  publisher = {{Springer, Berlin, Heidelberg}},
  date = {2011-08-26},
  pages = {119-129},
  author = {Larasati, Septina Dian and Kuboň, Vladislav and Zeman, Daniel},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Conference Paper/Larasati et al_2011_Indonesian Morphology Tool (MorphInd).pdf}
}

@inproceedings{nomoto_malindo_2018,
  title = {{{MALINDO Morph}}: {{Morphological}} Dictionary and Analyser for {{Malay}}/{{Indonesian}}},
  url = {http://lrec-conf.org/workshops/lrec2018/W29/pdf/8_W29.pdf},
  booktitle = {Proceedings of the {{LREC}} 2018 {{Workshop}} "{{The}} 13th {{Workshop}} on {{Asian Language Resources}}"},
  date = {2018},
  pages = {36-43},
  author = {Nomoto, Hiroki and Choi, Hannah and Moeljadi, David and Bond, Francis},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Conference Paper/Nomoto et al_2018_MALINDO Morph.pdf}
}

@software{maechler_cluster_2018,
  title = {Cluster: {{Cluster Analysis Basics}} and {{Extensions}}},
  date = {2018},
  author = {Maechler, Martin and Rousseeuw, Peter and Struyf, Anja and Hubert, Mia and Hornik, Kurt}
}

@article{galili_dendextend_2015,
  title = {Dendextend: An {{R}} Package for Visualizing, Adjusting, and Comparing Trees of Hierarchical Clustering},
  doi = {10.1093/bioinformatics/btv428},
  journaltitle = {Bioinformatics},
  date = {2015},
  author = {Galili, Tal}
}

@software{schmidt_wordvectors_2017,
  title = {{{wordVectors}}: {{Tools}} for Creating and Analyzing Vector-Space Models of Texts},
  url = {http://github.com/bmschmidt/wordVectors},
  version = {2.0},
  date = {2017},
  author = {Schmidt, Ben and Li, Jian}
}

@book{wickham_r_2017,
  location = {{Canada}},
  title = {R for {{Data Science}}},
  url = {http://r4ds.had.co.nz/},
  abstract = {This book will teach you how to do data science with R: You’ll learn how to get your data into R, get it into the most useful structure, transform it, visualise it and model it. In this book, you will find a practicum of skills for data science. Just as a chemist learns how to clean test tubes and stock a lab, you’ll learn how to clean data and draw plots—and many other things besides. These are the skills that allow data science to happen, and here you will find the best practices for doing each of these things with R. You’ll learn how to use the grammar of graphics, literate programming, and reproducible research to save time. You’ll also learn how to manage cognitive resources to facilitate discoveries when wrangling, visualising, and exploring data.},
  publisher = {{O'Reilly}},
  urldate = {2017-03-07},
  date = {2017},
  author = {Wickham, Hadley and Grolemund, Garrett},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Book/Wickham_Grolemund_2017_R for Data Science.pdf}
}

@book{sneddon_indonesian_2010,
  langid = {english},
  location = {{Crows Nest, New South Wales, Australia}},
  title = {Indonesian Reference Grammar},
  edition = {2nd},
  isbn = {978 1 74237 135 1},
  pagetotal = {401},
  publisher = {{Allen \& Unwin}},
  date = {2010},
  author = {Sneddon, James Neil and Adelaar, Alexander and Djenar, Dwi Noverini and Ewing, Michael C.},
  file = {/Users/Primahadi/Documents/_Zotero Digital Library/Book/Sneddon et al_2010_Indonesian Reference Grammar.pdf}
}
